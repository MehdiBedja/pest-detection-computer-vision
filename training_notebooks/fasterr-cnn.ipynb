{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10744147,"sourceType":"datasetVersion","datasetId":6662950}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tensorflow 2 Object Detection: Train model\n\n","metadata":{"id":"GaTTQ6iSRVZx"}},{"cell_type":"markdown","source":"<table align=\"left\"><td>\n  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb\">\n    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n  </a>\n</td><td>\n  <a target=\"_blank\"  href=\"https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb\">\n    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n</td></table>","metadata":{"id":"IYfnqP0PVcW-"}},{"cell_type":"markdown","source":"## Installation\n\nInstalling the Tensorflow Object Detection API became a lot easier with the relase of Tensorflow 2. The following few cells are all that is needed in order to install the OD API.","metadata":{"id":"KNT9cI_ZSCla"}},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjck8MmTl9cJ","outputId":"42c08c21-a2f2-4b03-d4f2-88c11864d4f0","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T21:20:08.139367Z","iopub.execute_input":"2025-02-13T21:20:08.139652Z","iopub.status.idle":"2025-02-13T21:20:21.723271Z","shell.execute_reply.started":"2025-02-13T21:20:08.139631Z","shell.execute_reply":"2025-02-13T21:20:21.722415Z"}},"outputs":[{"name":"stdout","text":"2.17.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\n\n# Clone the tensorflow models repository if it doesn't already exist\nif \"models\" in pathlib.Path.cwd().parts:\n  while \"models\" in pathlib.Path.cwd().parts:\n    os.chdir('..')\nelif not pathlib.Path('models').exists():\n  !git clone --depth 1 https://github.com/tensorflow/models","metadata":{"id":"Kpha2-F_SGBj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a2ddcd7-f32a-41f6-a381-bc65998b3a56","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:36:36.625501Z","iopub.execute_input":"2025-02-14T10:36:36.625747Z","iopub.status.idle":"2025-02-14T10:36:40.643514Z","shell.execute_reply.started":"2025-02-14T10:36:36.625726Z","shell.execute_reply":"2025-02-14T10:36:40.642615Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'models'...\nremote: Enumerating objects: 4306, done.\u001b[K\nremote: Counting objects: 100% (4306/4306), done.\u001b[K\nremote: Compressing objects: 100% (3325/3325), done.\u001b[K\nremote: Total 4306 (delta 1208), reused 2096 (delta 908), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (4306/4306), 53.17 MiB | 38.75 MiB/s, done.\nResolving deltas: 100% (1208/1208), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!sed -i 's/experimental.SyncBatchNormalization/BatchNormalization/' /kaggle/working/models/research/object_detection/core/freezable_sync_batch_norm.py\n","metadata":{"id":"IpnHwh8edk8D","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:37:03.563280Z","iopub.execute_input":"2025-02-14T10:37:03.563634Z","iopub.status.idle":"2025-02-14T10:37:03.682860Z","shell.execute_reply.started":"2025-02-14T10:37:03.563603Z","shell.execute_reply":"2025-02-14T10:37:03.681674Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!find / -name \"freezable_sync_batch_norm.py\" 2>/dev/null\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:37:09.582154Z","iopub.execute_input":"2025-02-14T10:37:09.582472Z","iopub.status.idle":"2025-02-14T10:37:42.734080Z","shell.execute_reply.started":"2025-02-14T10:37:09.582446Z","shell.execute_reply":"2025-02-14T10:37:42.733039Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/models/research/object_detection/core/freezable_sync_batch_norm.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%cd models/research\n\n# Compile Protos\n!protoc object_detection/protos/*.proto --python_out=.\n\n# Install the Object Detection API\n!cp object_detection/packages/tf2/setup.py .\n!pip install .","metadata":{"id":"rmr2UdV_SHuc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b3a3ddae-72c8-4cc3-afe1-6d0b988701fe","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:37:42.735442Z","iopub.execute_input":"2025-02-14T10:37:42.735707Z","iopub.status.idle":"2025-02-14T10:39:29.890861Z","shell.execute_reply.started":"2025-02-14T10:37:42.735686Z","shell.execute_reply":"2025-02-14T10:39:29.889987Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/models/research\nProcessing /kaggle/working/models/research\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting avro-python3 (from object_detection==0.1)\n  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting apache-beam (from object_detection==0.1)\n  Downloading apache_beam-2.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (11.0.0)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (5.3.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.7.5)\nRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.0.11)\nCollecting contextlib2 (from object_detection==0.1)\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.17.0)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\nCollecting lvis (from object_detection==0.1)\n  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.3)\nCollecting tf-models-official>=2.5.1 (from object_detection==0.1)\n  Downloading tf_models_official-2.18.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.37.1)\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.5.0)\nCollecting pyparsing==2.4.7 (from object_detection==0.1)\n  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\nCollecting sacrebleu<=2.2.0 (from object_detection==0.1)\n  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\nCollecting ai-edge-litert>=1.0.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n  Downloading ai_edge_litert-1.1.2-cp310-cp310-manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\nRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.155.0)\nRequirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.1)\nRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.6.17)\nRequirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.10.0.84)\nRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\nRequirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.2)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\nCollecting seqeval (from tf-models-official>=2.5.1->object_detection==0.1)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.7)\nRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\nCollecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\nCollecting tensorflow-text~=2.18.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n  Downloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting tensorflow~=2.18.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.17.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2025.1)\nRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\nCollecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n  Downloading crcmod-1.7.tar.gz (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.10.12)\nCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting cloudpickle~=2.2.1 (from apache-beam->object_detection==0.1)\n  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\nCollecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\nCollecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\n  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n  Downloading hdfs-2.7.3.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\nCollecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\nCollecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.2)\nRequirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.11)\nRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.25.0)\nRequirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.20.3)\nCollecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\nCollecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\nRequirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\nCollecting zstandard<1,>=0.18.0 (from apache-beam->object_detection==0.1)\n  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting pyarrow<17.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (3.12.1)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.13.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.4.1)\nRequirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.7)\nRequirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.3.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.55.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (24.3.25)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.27.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.34.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.1.1)\nCollecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.22.3)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2025.1.31)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (4.67.1)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.3.0)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (2.4.1)\nRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.7.0)\nRequirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (5.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.10)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (75.1.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (2.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (1.17.0)\nCollecting tensorboard<2.19,>=2.18 (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1)\n  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.8)\nINFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\nCollecting tf-keras>=2.16.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.1)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (2.19.1)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (8.1.7)\nRequirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\nRequirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.6)\nRequirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.13.1)\nRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\nRequirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\nRequirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.11.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (0.45.1)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2024.9.0)\nRequirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (5.13.0)\nRequirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.21.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.66.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (5.5.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.5.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (2024.2.0)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\nRequirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.16)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu<=2.2.0->object_detection==0.1) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.2)\nDownloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_models_official-2.18.0-py2.py3-none-any.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading apache_beam-2.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nDownloading lvis-0.5.3-py3-none-any.whl (14 kB)\nDownloading ai_edge_litert-1.1.2-cp310-cp310-manylinux_2_17_x86_64.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nDownloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\nDownloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading objsize-0.7.1-py3-none-any.whl (11 kB)\nDownloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\nDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: object_detection, avro-python3, crcmod, dill, hdfs, seqeval, docopt\n  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=21920524 sha256=b0c10014732ae46880fa84045bbd462cd81a3171f4c0ef3096d37a384b4af242\n  Stored in directory: /tmp/pip-ephem-wheel-cache-jcxvcm_6/wheels/e6/5c/1f/32444df4025257dccdc9eafab2d06b65752494ee9ca01a388c\n  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43994 sha256=d7f35194be9e786b4a900a0a9baa84cddf1d63e153478c418b70144ec2869d1a\n  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=dba0f0eccdb492dc9f2276e4bbf194b0a5e740089e3d1ae6413c17139c58452c\n  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=5df4651c68a22e92402505d1bab2d4396fbfac47b617a122f9e37d0ff56e1eca\n  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=c6a910c352fe454fa257bb91f08544327bdc94ae150e42766fa7f784c8455fd3\n  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=4c31d40ac89a5998fd68059fd7aae88d756ca4c95a70bb748435c9deb975dafa\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c2999e125d14e62a6263f0c963d438f17e61ef830fc0140ec3a59c0174991bb4\n  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\nSuccessfully built object_detection avro-python3 crcmod dill hdfs seqeval docopt\nInstalling collected packages: docopt, crcmod, zstandard, redis, pyparsing, pyarrow-hotfix, portalocker, objsize, jsonpickle, grpcio, fasteners, fastavro, dill, contextlib2, cloudpickle, avro-python3, pydot, hdfs, tensorboard, tensorflow, tf-keras, pyarrow, tensorflow-text, tensorflow-model-optimization, seqeval, sacrebleu, ai-edge-litert, tf-models-official, lvis, apache-beam, object_detection\n  Attempting uninstall: pyparsing\n    Found existing installation: pyparsing 3.2.0\n    Uninstalling pyparsing-3.2.0:\n      Successfully uninstalled pyparsing-3.2.0\n  Attempting uninstall: jsonpickle\n    Found existing installation: jsonpickle 4.0.1\n    Uninstalling jsonpickle-4.0.1:\n      Successfully uninstalled jsonpickle-4.0.1\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.68.1\n    Uninstalling grpcio-1.68.1:\n      Successfully uninstalled grpcio-1.68.1\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: cloudpickle\n    Found existing installation: cloudpickle 3.1.0\n    Uninstalling cloudpickle-3.1.0:\n      Successfully uninstalled cloudpickle-3.1.0\n  Attempting uninstall: pydot\n    Found existing installation: pydot 3.0.3\n    Uninstalling pydot-3.0.3:\n      Successfully uninstalled pydot-3.0.3\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.17.1\n    Uninstalling tensorboard-2.17.1:\n      Successfully uninstalled tensorboard-2.17.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.17.1\n    Uninstalling tensorflow-2.17.1:\n      Successfully uninstalled tensorflow-2.17.1\n  Attempting uninstall: tf-keras\n    Found existing installation: tf_keras 2.17.0\n    Uninstalling tf_keras-2.17.0:\n      Successfully uninstalled tf_keras-2.17.0\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.0\n    Uninstalling pyarrow-19.0.0:\n      Successfully uninstalled pyarrow-19.0.0\n  Attempting uninstall: tensorflow-text\n    Found existing installation: tensorflow-text 2.17.0\n    Uninstalling tensorflow-text-2.17.0:\n      Successfully uninstalled tensorflow-text-2.17.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask 2024.11.2 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\ndistributed 2024.11.2 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nmultiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ai-edge-litert-1.1.2 apache-beam-2.62.0 avro-python3-1.10.2 cloudpickle-2.2.1 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 lvis-0.5.3 object_detection-0.1 objsize-0.7.1 portalocker-3.1.1 pyarrow-16.1.0 pyarrow-hotfix-0.6 pydot-1.4.2 pyparsing-2.4.7 redis-5.2.1 sacrebleu-2.2.0 seqeval-1.2.2 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.18.1 tf-keras-2.18.0 tf-models-official-2.18.0 zstandard-0.23.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install tensorflow==2.15.1\n\n","metadata":{"id":"fTBYWlnKSD78","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b65d78b6-24ce-4864-bfb7-5e56707e6409","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:39:44.769142Z","iopub.execute_input":"2025-02-14T10:39:44.769462Z","iopub.status.idle":"2025-02-14T10:40:21.527903Z","shell.execute_reply.started":"2025-02-14T10:39:44.769436Z","shell.execute_reply":"2025-02-14T10:40:21.526917Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.15.1\n  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (18.1.1)\nCollecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (4.12.2)\nCollecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.1)\n  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.65.5)\nCollecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.1)\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras<2.16,>=2.15.0 (from tensorflow==2.15.1)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.45.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (2.4.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.27.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.7)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.1.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.1) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\nDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, keras, tensorboard, ml-dtypes, tensorflow\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.17.0\n    Uninstalling wrapt-1.17.0:\n      Successfully uninstalled wrapt-1.17.0\n  Attempting uninstall: keras\n    Found existing installation: keras 3.5.0\n    Uninstalling keras-3.5.0:\n      Successfully uninstalled keras-3.5.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.18.0\n    Uninstalling tensorflow-2.18.0:\n      Successfully uninstalled tensorflow-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.15.1 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.1 which is incompatible.\ntf-models-official 2.18.0 requires tensorflow~=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.3.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 wrapt-1.14.1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#run model builder test\n!python /kaggle/working/models/research/object_detection/builders/model_builder_tf2_test.py\n","metadata":{"id":"XzXxTBXHSNqA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bacb6f0a-bf62-46a5-fdd3-b383ba7f27ba","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:40:42.685769Z","iopub.execute_input":"2025-02-14T10:40:42.686078Z","iopub.status.idle":"2025-02-14T10:41:25.134255Z","shell.execute_reply.started":"2025-02-14T10:40:42.686055Z","shell.execute_reply":"2025-02-14T10:41:25.133212Z"}},"outputs":[{"name":"stdout","text":"2025-02-14 10:40:43.454342: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-14 10:40:43.454395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-14 10:40:43.456223: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nRunning tests under Python 3.10.12: /usr/bin/python3\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\nW0214 10:40:51.450586 133019446174848 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n/usr/local/lib/python3.10/dist-packages/object_detection/builders/model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n  logging.warn(('Building experimental DeepMAC meta-arch.'\nW0214 10:40:51.723838 133019446174848 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\nI0214 10:40:52.034268 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.88s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\nI0214 10:40:52.863762 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.83s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\nI0214 10:40:53.177517 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\nI0214 10:40:53.491861 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.31s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\nI0214 10:40:55.644883 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.15s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\nI0214 10:40:55.658029 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\nI0214 10:40:55.684555 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\nI0214 10:40:55.702128 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\nI0214 10:40:55.720495 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\nI0214 10:40:55.828185 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\nI0214 10:40:55.929933 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\nI0214 10:40:56.035655 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\nI0214 10:40:56.140588 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\nI0214 10:40:56.242906 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\nI0214 10:40:56.274488 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\nI0214 10:40:56.464200 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\nI0214 10:40:56.464351 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\nI0214 10:40:56.464432 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\nI0214 10:40:56.469596 133019446174848 efficientnet_model.py:143] round_filter input=32 output=32\nI0214 10:40:56.697306 133019446174848 efficientnet_model.py:143] round_filter input=32 output=32\nI0214 10:40:56.697506 133019446174848 efficientnet_model.py:143] round_filter input=16 output=16\nI0214 10:40:56.779054 133019446174848 efficientnet_model.py:143] round_filter input=16 output=16\nI0214 10:40:56.779233 133019446174848 efficientnet_model.py:143] round_filter input=24 output=24\nI0214 10:40:56.984492 133019446174848 efficientnet_model.py:143] round_filter input=24 output=24\nI0214 10:40:56.984671 133019446174848 efficientnet_model.py:143] round_filter input=40 output=40\nI0214 10:40:57.183603 133019446174848 efficientnet_model.py:143] round_filter input=40 output=40\nI0214 10:40:57.183761 133019446174848 efficientnet_model.py:143] round_filter input=80 output=80\nI0214 10:40:57.478192 133019446174848 efficientnet_model.py:143] round_filter input=80 output=80\nI0214 10:40:57.478362 133019446174848 efficientnet_model.py:143] round_filter input=112 output=112\nI0214 10:40:57.769308 133019446174848 efficientnet_model.py:143] round_filter input=112 output=112\nI0214 10:40:57.769479 133019446174848 efficientnet_model.py:143] round_filter input=192 output=192\nI0214 10:40:58.160058 133019446174848 efficientnet_model.py:143] round_filter input=192 output=192\nI0214 10:40:58.160248 133019446174848 efficientnet_model.py:143] round_filter input=320 output=320\nI0214 10:40:58.256071 133019446174848 efficientnet_model.py:143] round_filter input=1280 output=1280\nI0214 10:40:58.300961 133019446174848 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0214 10:40:58.356551 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\nI0214 10:40:58.356695 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\nI0214 10:40:58.356808 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\nI0214 10:40:58.358730 133019446174848 efficientnet_model.py:143] round_filter input=32 output=32\nI0214 10:40:58.375118 133019446174848 efficientnet_model.py:143] round_filter input=32 output=32\nI0214 10:40:58.375243 133019446174848 efficientnet_model.py:143] round_filter input=16 output=16\nI0214 10:40:58.514735 133019446174848 efficientnet_model.py:143] round_filter input=16 output=16\nI0214 10:40:58.514870 133019446174848 efficientnet_model.py:143] round_filter input=24 output=24\nI0214 10:40:58.789923 133019446174848 efficientnet_model.py:143] round_filter input=24 output=24\nI0214 10:40:58.790080 133019446174848 efficientnet_model.py:143] round_filter input=40 output=40\nI0214 10:40:59.058000 133019446174848 efficientnet_model.py:143] round_filter input=40 output=40\nI0214 10:40:59.058156 133019446174848 efficientnet_model.py:143] round_filter input=80 output=80\nI0214 10:40:59.395981 133019446174848 efficientnet_model.py:143] round_filter input=80 output=80\nI0214 10:40:59.396158 133019446174848 efficientnet_model.py:143] round_filter input=112 output=112\nI0214 10:40:59.740887 133019446174848 efficientnet_model.py:143] round_filter input=112 output=112\nI0214 10:40:59.741067 133019446174848 efficientnet_model.py:143] round_filter input=192 output=192\nI0214 10:41:00.177248 133019446174848 efficientnet_model.py:143] round_filter input=192 output=192\nI0214 10:41:00.177424 133019446174848 efficientnet_model.py:143] round_filter input=320 output=320\nI0214 10:41:00.364121 133019446174848 efficientnet_model.py:143] round_filter input=1280 output=1280\nI0214 10:41:00.398146 133019446174848 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0214 10:41:00.461860 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\nI0214 10:41:00.462007 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\nI0214 10:41:00.462073 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\nI0214 10:41:00.464046 133019446174848 efficientnet_model.py:143] round_filter input=32 output=32\nI0214 10:41:00.482084 133019446174848 efficientnet_model.py:143] round_filter input=32 output=32\nI0214 10:41:00.482223 133019446174848 efficientnet_model.py:143] round_filter input=16 output=16\nI0214 10:41:00.613831 133019446174848 efficientnet_model.py:143] round_filter input=16 output=16\nI0214 10:41:00.613974 133019446174848 efficientnet_model.py:143] round_filter input=24 output=24\nI0214 10:41:00.865330 133019446174848 efficientnet_model.py:143] round_filter input=24 output=24\nI0214 10:41:00.865484 133019446174848 efficientnet_model.py:143] round_filter input=40 output=48\nI0214 10:41:01.151260 133019446174848 efficientnet_model.py:143] round_filter input=40 output=48\nI0214 10:41:01.151427 133019446174848 efficientnet_model.py:143] round_filter input=80 output=88\nI0214 10:41:01.544507 133019446174848 efficientnet_model.py:143] round_filter input=80 output=88\nI0214 10:41:01.544712 133019446174848 efficientnet_model.py:143] round_filter input=112 output=120\nI0214 10:41:01.941374 133019446174848 efficientnet_model.py:143] round_filter input=112 output=120\nI0214 10:41:01.941591 133019446174848 efficientnet_model.py:143] round_filter input=192 output=208\nI0214 10:41:02.422608 133019446174848 efficientnet_model.py:143] round_filter input=192 output=208\nI0214 10:41:02.422796 133019446174848 efficientnet_model.py:143] round_filter input=320 output=352\nI0214 10:41:02.616942 133019446174848 efficientnet_model.py:143] round_filter input=1280 output=1408\nI0214 10:41:02.654098 133019446174848 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0214 10:41:02.716387 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\nI0214 10:41:02.716529 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\nI0214 10:41:02.716629 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\nI0214 10:41:02.718429 133019446174848 efficientnet_model.py:143] round_filter input=32 output=40\nI0214 10:41:02.739023 133019446174848 efficientnet_model.py:143] round_filter input=32 output=40\nI0214 10:41:02.739161 133019446174848 efficientnet_model.py:143] round_filter input=16 output=24\nI0214 10:41:02.899690 133019446174848 efficientnet_model.py:143] round_filter input=16 output=24\nI0214 10:41:02.899859 133019446174848 efficientnet_model.py:143] round_filter input=24 output=32\nI0214 10:41:03.195792 133019446174848 efficientnet_model.py:143] round_filter input=24 output=32\nI0214 10:41:03.195971 133019446174848 efficientnet_model.py:143] round_filter input=40 output=48\nI0214 10:41:03.470791 133019446174848 efficientnet_model.py:143] round_filter input=40 output=48\nI0214 10:41:03.470986 133019446174848 efficientnet_model.py:143] round_filter input=80 output=96\nI0214 10:41:03.950484 133019446174848 efficientnet_model.py:143] round_filter input=80 output=96\nI0214 10:41:03.950687 133019446174848 efficientnet_model.py:143] round_filter input=112 output=136\nI0214 10:41:04.697720 133019446174848 efficientnet_model.py:143] round_filter input=112 output=136\nI0214 10:41:04.697924 133019446174848 efficientnet_model.py:143] round_filter input=192 output=232\nI0214 10:41:05.297085 133019446174848 efficientnet_model.py:143] round_filter input=192 output=232\nI0214 10:41:05.297298 133019446174848 efficientnet_model.py:143] round_filter input=320 output=384\nI0214 10:41:05.495402 133019446174848 efficientnet_model.py:143] round_filter input=1280 output=1536\nI0214 10:41:05.534765 133019446174848 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0214 10:41:05.604180 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\nI0214 10:41:05.604341 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\nI0214 10:41:05.604446 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\nI0214 10:41:05.606266 133019446174848 efficientnet_model.py:143] round_filter input=32 output=48\nI0214 10:41:05.627253 133019446174848 efficientnet_model.py:143] round_filter input=32 output=48\nI0214 10:41:05.627394 133019446174848 efficientnet_model.py:143] round_filter input=16 output=24\nI0214 10:41:05.770219 133019446174848 efficientnet_model.py:143] round_filter input=16 output=24\nI0214 10:41:05.770401 133019446174848 efficientnet_model.py:143] round_filter input=24 output=32\nI0214 10:41:06.119211 133019446174848 efficientnet_model.py:143] round_filter input=24 output=32\nI0214 10:41:06.119397 133019446174848 efficientnet_model.py:143] round_filter input=40 output=56\nI0214 10:41:06.499896 133019446174848 efficientnet_model.py:143] round_filter input=40 output=56\nI0214 10:41:06.500057 133019446174848 efficientnet_model.py:143] round_filter input=80 output=112\nI0214 10:41:07.079083 133019446174848 efficientnet_model.py:143] round_filter input=80 output=112\nI0214 10:41:07.079298 133019446174848 efficientnet_model.py:143] round_filter input=112 output=160\nI0214 10:41:07.663736 133019446174848 efficientnet_model.py:143] round_filter input=112 output=160\nI0214 10:41:07.663953 133019446174848 efficientnet_model.py:143] round_filter input=192 output=272\nI0214 10:41:08.466793 133019446174848 efficientnet_model.py:143] round_filter input=192 output=272\nI0214 10:41:08.467004 133019446174848 efficientnet_model.py:143] round_filter input=320 output=448\nI0214 10:41:08.664353 133019446174848 efficientnet_model.py:143] round_filter input=1280 output=1792\nI0214 10:41:08.703109 133019446174848 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0214 10:41:08.780787 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\nI0214 10:41:08.780992 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\nI0214 10:41:08.781113 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\nI0214 10:41:08.783058 133019446174848 efficientnet_model.py:143] round_filter input=32 output=48\nI0214 10:41:08.800866 133019446174848 efficientnet_model.py:143] round_filter input=32 output=48\nI0214 10:41:08.801010 133019446174848 efficientnet_model.py:143] round_filter input=16 output=24\nI0214 10:41:09.011849 133019446174848 efficientnet_model.py:143] round_filter input=16 output=24\nI0214 10:41:09.012024 133019446174848 efficientnet_model.py:143] round_filter input=24 output=40\nI0214 10:41:09.483638 133019446174848 efficientnet_model.py:143] round_filter input=24 output=40\nI0214 10:41:09.483820 133019446174848 efficientnet_model.py:143] round_filter input=40 output=64\nI0214 10:41:09.979671 133019446174848 efficientnet_model.py:143] round_filter input=40 output=64\nI0214 10:41:09.979884 133019446174848 efficientnet_model.py:143] round_filter input=80 output=128\nI0214 10:41:10.667152 133019446174848 efficientnet_model.py:143] round_filter input=80 output=128\nI0214 10:41:10.667343 133019446174848 efficientnet_model.py:143] round_filter input=112 output=176\nI0214 10:41:11.354924 133019446174848 efficientnet_model.py:143] round_filter input=112 output=176\nI0214 10:41:11.355117 133019446174848 efficientnet_model.py:143] round_filter input=192 output=304\nI0214 10:41:12.256428 133019446174848 efficientnet_model.py:143] round_filter input=192 output=304\nI0214 10:41:12.256644 133019446174848 efficientnet_model.py:143] round_filter input=320 output=512\nI0214 10:41:12.556171 133019446174848 efficientnet_model.py:143] round_filter input=1280 output=2048\nI0214 10:41:12.593007 133019446174848 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0214 10:41:12.681860 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\nI0214 10:41:12.682009 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\nI0214 10:41:12.682087 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\nI0214 10:41:12.683915 133019446174848 efficientnet_model.py:143] round_filter input=32 output=56\nI0214 10:41:12.704266 133019446174848 efficientnet_model.py:143] round_filter input=32 output=56\nI0214 10:41:12.704391 133019446174848 efficientnet_model.py:143] round_filter input=16 output=32\nI0214 10:41:12.934161 133019446174848 efficientnet_model.py:143] round_filter input=16 output=32\nI0214 10:41:12.934334 133019446174848 efficientnet_model.py:143] round_filter input=24 output=40\nI0214 10:41:13.768568 133019446174848 efficientnet_model.py:143] round_filter input=24 output=40\nI0214 10:41:13.768787 133019446174848 efficientnet_model.py:143] round_filter input=40 output=72\nI0214 10:41:14.363344 133019446174848 efficientnet_model.py:143] round_filter input=40 output=72\nI0214 10:41:14.363552 133019446174848 efficientnet_model.py:143] round_filter input=80 output=144\nI0214 10:41:15.159887 133019446174848 efficientnet_model.py:143] round_filter input=80 output=144\nI0214 10:41:15.160114 133019446174848 efficientnet_model.py:143] round_filter input=112 output=200\nI0214 10:41:15.946025 133019446174848 efficientnet_model.py:143] round_filter input=112 output=200\nI0214 10:41:15.946227 133019446174848 efficientnet_model.py:143] round_filter input=192 output=344\nI0214 10:41:17.098356 133019446174848 efficientnet_model.py:143] round_filter input=192 output=344\nI0214 10:41:17.098607 133019446174848 efficientnet_model.py:143] round_filter input=320 output=576\nI0214 10:41:17.422258 133019446174848 efficientnet_model.py:143] round_filter input=1280 output=2304\nI0214 10:41:17.460313 133019446174848 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0214 10:41:17.561961 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\nI0214 10:41:17.562121 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\nI0214 10:41:17.562239 133019446174848 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\nI0214 10:41:17.564175 133019446174848 efficientnet_model.py:143] round_filter input=32 output=64\nI0214 10:41:17.585101 133019446174848 efficientnet_model.py:143] round_filter input=32 output=64\nI0214 10:41:17.585237 133019446174848 efficientnet_model.py:143] round_filter input=16 output=32\nI0214 10:41:17.878259 133019446174848 efficientnet_model.py:143] round_filter input=16 output=32\nI0214 10:41:17.878450 133019446174848 efficientnet_model.py:143] round_filter input=24 output=48\nI0214 10:41:18.547955 133019446174848 efficientnet_model.py:143] round_filter input=24 output=48\nI0214 10:41:18.548155 133019446174848 efficientnet_model.py:143] round_filter input=40 output=80\nI0214 10:41:19.240333 133019446174848 efficientnet_model.py:143] round_filter input=40 output=80\nI0214 10:41:19.240595 133019446174848 efficientnet_model.py:143] round_filter input=80 output=160\nI0214 10:41:20.242901 133019446174848 efficientnet_model.py:143] round_filter input=80 output=160\nI0214 10:41:20.243099 133019446174848 efficientnet_model.py:143] round_filter input=112 output=224\nI0214 10:41:21.211423 133019446174848 efficientnet_model.py:143] round_filter input=112 output=224\nI0214 10:41:21.211667 133019446174848 efficientnet_model.py:143] round_filter input=192 output=384\nI0214 10:41:22.492495 133019446174848 efficientnet_model.py:143] round_filter input=192 output=384\nI0214 10:41:22.492707 133019446174848 efficientnet_model.py:143] round_filter input=320 output=640\nI0214 10:41:22.898606 133019446174848 efficientnet_model.py:143] round_filter input=1280 output=2560\nI0214 10:41:22.937594 133019446174848 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0214 10:41:23.375064 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.1s\n[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\nI0214 10:41:23.532572 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\nI0214 10:41:23.534399 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\nI0214 10:41:23.534981 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\nI0214 10:41:23.536585 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n[ RUN      ] ModelBuilderTF2Test.test_session\n[  SKIPPED ] ModelBuilderTF2Test.test_session\n[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\nI0214 10:41:23.537927 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\nI0214 10:41:23.538396 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\nI0214 10:41:23.539489 133019446174848 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n----------------------------------------------------------------------\nRan 24 tests in 32.386s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install protobuf==3.20.*\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"id":"rSfDK-Ko960J","outputId":"b1d8a300-45a0-4d35-b554-b95f8d088c72","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:41:31.544640Z","iopub.execute_input":"2025-02-14T10:41:31.544959Z","iopub.status.idle":"2025-02-14T10:41:34.873034Z","shell.execute_reply.started":"2025-02-14T10:41:31.544932Z","shell.execute_reply":"2025-02-14T10:41:34.871980Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/dist-packages (3.20.3)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Prepare data","metadata":{"id":"Iz1sd2reSTxg"}},{"cell_type":"code","source":"cp -r /kaggle/input/dataset13pesttfrecords /kaggle/working/dataset\n","metadata":{"id":"cozgoQPEbo-k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5086182-8dea-43b9-8d14-594b7ce12885","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:41:38.591161Z","iopub.execute_input":"2025-02-14T10:41:38.591467Z","iopub.status.idle":"2025-02-14T10:41:44.458913Z","shell.execute_reply.started":"2025-02-14T10:41:38.591443Z","shell.execute_reply":"2025-02-14T10:41:44.457890Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Retrieve generate_tfrecord.py and labelmap\nThere are multiple ways to do this, I have included the files needed within my Kaggle dataset, but you could also download them from Github, or even connect your Google Drive and retrieve them that way","metadata":{"id":"YawyVBRvuTTE"}},{"cell_type":"code","source":"train_record_path = '/kaggle/working/dataset/train.record'\nval_record_path = '/kaggle/working/dataset/val.record'\ntest_record_path = '/kaggle/working/dataset/test.record'\nlabelmap_path = '/kaggle/working/dataset/label_map.pbtxt'","metadata":{"id":"Z_W_8L24c4Sk","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:43:02.103109Z","iopub.execute_input":"2025-02-14T10:43:02.103437Z","iopub.status.idle":"2025-02-14T10:43:02.107404Z","shell.execute_reply.started":"2025-02-14T10:43:02.103409Z","shell.execute_reply":"2025-02-14T10:43:02.106393Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Configuring training\n\nNow that the data is ready it's time to create a training configuration. The OD API supports lots of models, each with its own config file. In this notebook I'm making use of EfficientDet, but you can replace it with any model available in the [Tensorflow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).","metadata":{"id":"SK79i98YSY8a"}},{"cell_type":"code","source":"batch_size = 8\nnum_steps = 45500  # (from earlier)\nnum_eval_steps = 135","metadata":{"id":"Axko9Jd0hEI3","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:43:04.862889Z","iopub.execute_input":"2025-02-14T10:43:04.863157Z","iopub.status.idle":"2025-02-14T10:43:04.866665Z","shell.execute_reply.started":"2025-02-14T10:43:04.863137Z","shell.execute_reply":"2025-02-14T10:43:04.865836Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n!tar -xf faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz","metadata":{"id":"8RNI68K_dyzX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f505a836-3bc9-47f1-eef0-90721ab375ca","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:43:06.792531Z","iopub.execute_input":"2025-02-14T10:43:06.792847Z","iopub.status.idle":"2025-02-14T10:43:10.257225Z","shell.execute_reply.started":"2025-02-14T10:43:06.792825Z","shell.execute_reply":"2025-02-14T10:43:10.256137Z"}},"outputs":[{"name":"stdout","text":"--2025-02-14 10:43:06--  http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\nResolving download.tensorflow.org (download.tensorflow.org)... 209.85.200.207, 192.178.129.207, 173.194.193.207, ...\nConnecting to download.tensorflow.org (download.tensorflow.org)|209.85.200.207|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 211996178 (202M) [application/x-tar]\nSaving to: ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’\n\nfaster_rcnn_resnet5 100%[===================>] 202.17M   214MB/s    in 0.9s    \n\n2025-02-14 10:43:07 (214 MB/s) - ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’ saved [211996178/211996178]\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"fine_tune_checkpoint = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0'","metadata":{"id":"HKENdH3TfhGb","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:43:25.695023Z","iopub.execute_input":"2025-02-14T10:43:25.695318Z","iopub.status.idle":"2025-02-14T10:43:25.699184Z","shell.execute_reply.started":"2025-02-14T10:43:25.695296Z","shell.execute_reply":"2025-02-14T10:43:25.698445Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config\n\nbase_config_path = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config'","metadata":{"id":"qzQ84qIQelJB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"63c21ba4-9fc8-46f1-fbea-a83d3b0dec30","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:43:30.312016Z","iopub.execute_input":"2025-02-14T10:43:30.312302Z","iopub.status.idle":"2025-02-14T10:43:30.556736Z","shell.execute_reply.started":"2025-02-14T10:43:30.312280Z","shell.execute_reply":"2025-02-14T10:43:30.556087Z"}},"outputs":[{"name":"stdout","text":"--2025-02-14 10:43:30--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3559 (3.5K) [text/plain]\nSaving to: ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config’\n\nfaster_rcnn_resnet5 100%[===================>]   3.48K  --.-KB/s    in 0s      \n\n2025-02-14 10:43:30 (58.2 MB/s) - ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config’ saved [3559/3559]\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# edit configuration file (from https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD)\n\nimport re\n\nwith open(base_config_path) as f:\n    config = f.read()\n\nwith open('model_config.config', 'w') as f:\n\n  # Set labelmap path\n  config = re.sub('label_map_path: \".*?\"',\n             'label_map_path: \"{}\"'.format(labelmap_path), config)\n\n  # Set fine_tune_checkpoint path\n  config = re.sub('fine_tune_checkpoint: \".*?\"',\n                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n\n  # Set train tf-record file path\n  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")',\n                  'input_path: \"{}\"'.format(train_record_path), config)\n\n  # Set test tf-record file path\n  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")',\n                  'input_path: \"{}\"'.format(test_record_path), config)\n\n  # Set number of classes.\n  config = re.sub('num_classes: [0-9]+',\n                  'num_classes: {}'.format(13), config)\n\n  # Set batch size\n  config = re.sub('batch_size: [0-9]+',\n                  'batch_size: {}'.format(batch_size), config)\n\n  # Set training steps\n  config = re.sub('num_steps: [0-9]+',\n                  'num_steps: {}'.format(num_steps), config)\n\n  # Set fine-tune checkpoint type to detection\n  config = re.sub('fine_tune_checkpoint_type: \"classification\"',\n             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n\n  f.write(config)","metadata":{"id":"m3ehVTRgesxS","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:43:37.303427Z","iopub.execute_input":"2025-02-14T10:43:37.303772Z","iopub.status.idle":"2025-02-14T10:43:37.311388Z","shell.execute_reply.started":"2025-02-14T10:43:37.303743Z","shell.execute_reply":"2025-02-14T10:43:37.310620Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"%cat model_config.config","metadata":{"id":"SmtrS5dihpS_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa5ad186-9867-4594-d7bc-637bf3fc9ac0","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:43:42.433636Z","iopub.execute_input":"2025-02-14T10:43:42.433943Z","iopub.status.idle":"2025-02-14T10:43:42.553920Z","shell.execute_reply.started":"2025-02-14T10:43:42.433917Z","shell.execute_reply":"2025-02-14T10:43:42.552873Z"}},"outputs":[{"name":"stdout","text":"# Faster R-CNN with Resnet-50 (v1) with 640x640 input resolution\n# Trained on COCO, initialized from Imagenet classification checkpoint\n#\n# Train on TPU-8\n#\n# Achieves 29.3 mAP on COCO17 Val\n\nmodel {\n  faster_rcnn {\n    num_classes: 13\n    image_resizer {\n      keep_aspect_ratio_resizer {\n        min_dimension: 640\n        max_dimension: 640\n        pad_to_max_dimension: true\n      }\n    }\n    feature_extractor {\n      type: 'faster_rcnn_resnet50_keras'\n      batch_norm_trainable: true\n    }\n    first_stage_anchor_generator {\n      grid_anchor_generator {\n        scales: [0.25, 0.5, 1.0, 2.0]\n        aspect_ratios: [0.5, 1.0, 2.0]\n        height_stride: 16\n        width_stride: 16\n      }\n    }\n    first_stage_box_predictor_conv_hyperparams {\n      op: CONV\n      regularizer {\n        l2_regularizer {\n          weight: 0.0\n        }\n      }\n      initializer {\n        truncated_normal_initializer {\n          stddev: 0.01\n        }\n      }\n    }\n    first_stage_nms_score_threshold: 0.0\n    first_stage_nms_iou_threshold: 0.7\n    first_stage_max_proposals: 300\n    first_stage_localization_loss_weight: 2.0\n    first_stage_objectness_loss_weight: 1.0\n    initial_crop_size: 14\n    maxpool_kernel_size: 2\n    maxpool_stride: 2\n    second_stage_box_predictor {\n      mask_rcnn_box_predictor {\n        use_dropout: false\n        dropout_keep_probability: 1.0\n        fc_hyperparams {\n          op: FC\n          regularizer {\n            l2_regularizer {\n              weight: 0.0\n            }\n          }\n          initializer {\n            variance_scaling_initializer {\n              factor: 1.0\n              uniform: true\n              mode: FAN_AVG\n            }\n          }\n        }\n        share_box_across_classes: true\n      }\n    }\n    second_stage_post_processing {\n      batch_non_max_suppression {\n        score_threshold: 0.0\n        iou_threshold: 0.6\n        max_detections_per_class: 100\n        max_total_detections: 300\n      }\n      score_converter: SOFTMAX\n    }\n    second_stage_localization_loss_weight: 2.0\n    second_stage_classification_loss_weight: 1.0\n    use_static_shapes: true\n    use_matmul_crop_and_resize: true\n    clip_anchors_to_image: true\n    use_static_balanced_label_sampler: true\n    use_matmul_gather_in_matcher: true\n  }\n}\n\ntrain_config: {\n  batch_size: 8\n  sync_replicas: true\n  startup_delay_steps: 0\n  replicas_to_aggregate: 8\n  num_steps: 45500\n  optimizer {\n    momentum_optimizer: {\n      learning_rate: {\n        cosine_decay_learning_rate {\n          learning_rate_base: .04\n          total_steps: 25000\n          warmup_learning_rate: .013333\n          warmup_steps: 2000\n        }\n      }\n      momentum_optimizer_value: 0.9\n    }\n    use_moving_average: false\n  }\n  fine_tune_checkpoint_version: V2\n  fine_tune_checkpoint: \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n  fine_tune_checkpoint_type: \"detection\"\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n\n  max_number_of_boxes: 100\n  unpad_groundtruth_tensors: false\n  use_bfloat16: true  # works only on TPUs\n}\n\ntrain_input_reader: {\n  label_map_path: \"/kaggle/working/dataset/label_map.pbtxt\"\n  tf_record_input_reader {\n    input_path: \"/kaggle/working/dataset/train.record\"\n  }\n}\n\neval_config: {\n  metrics_set: \"coco_detection_metrics\"\n  use_moving_averages: false\n  batch_size: 8;\n}\n\neval_input_reader: {\n  label_map_path: \"/kaggle/working/dataset/label_map.pbtxt\"\n  shuffle: false\n  num_epochs: 1\n  tf_record_input_reader {\n    input_path: \"/kaggle/working/dataset/test.record\"\n  }\n}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"model_dir = \"/kaggle/working/trained_model\"\npipeline_config_path = 'model_config.config'","metadata":{"id":"eRTBSsYthwxG","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:44:12.984180Z","iopub.execute_input":"2025-02-14T10:44:12.984526Z","iopub.status.idle":"2025-02-14T10:44:12.988140Z","shell.execute_reply.started":"2025-02-14T10:44:12.984498Z","shell.execute_reply":"2025-02-14T10:44:12.987307Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Train detector","metadata":{"id":"Tv0sbQlciKWA"}},{"cell_type":"code","source":"# Run this block first and use the refresh arrow that will appear in the header once the training below starts\n%load_ext tensorboard\n%tensorboard --logdir 'training/train'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:44:53.154045Z","iopub.execute_input":"2025-02-14T10:44:53.154368Z","iopub.status.idle":"2025-02-14T10:44:57.671986Z","shell.execute_reply.started":"2025-02-14T10:44:53.154334Z","shell.execute_reply":"2025-02-14T10:44:57.671117Z"}},"outputs":[{"name":"stdout","text":"The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    "},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"!kill 216","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:44:50.769612Z","iopub.execute_input":"2025-02-14T10:44:50.769926Z","iopub.status.idle":"2025-02-14T10:44:50.885873Z","shell.execute_reply.started":"2025-02-14T10:44:50.769901Z","shell.execute_reply":"2025-02-14T10:44:50.884687Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"!pip uninstall tf_slim -y\n!pip install tf_slim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:45:27.562793Z","iopub.execute_input":"2025-02-14T10:45:27.563066Z","iopub.status.idle":"2025-02-14T10:45:32.346972Z","shell.execute_reply.started":"2025-02-14T10:45:27.563046Z","shell.execute_reply":"2025-02-14T10:45:32.346152Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: tf-slim 1.1.0\nUninstalling tf-slim-1.1.0:\n  Successfully uninstalled tf-slim-1.1.0\nCollecting tf_slim\n  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim) (1.4.0)\nDownloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tf_slim\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntf-models-official 2.18.0 requires tensorflow~=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tf_slim-1.1.0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n    --pipeline_config_path={pipeline_config_path} \\\n    --model_dir={model_dir} \\\n    --alsologtostderr \\\n    --num_train_steps={num_steps} \\\n    --sample_1_of_n_eval_examples=1 \\\n    --num_eval_steps={num_eval_steps} \\\n    --checkpoint_every_n=5000","metadata":{"id":"t2zxx5AXiNNK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"da3d0a42-faa7-4b30-8995-f0112b992ec1","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:48:35.116309Z","iopub.execute_input":"2025-02-14T10:48:35.116717Z"}},"outputs":[{"name":"stdout","text":"2025-02-14 10:48:35.648947: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-14 10:48:35.648997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-14 10:48:35.650564: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nI0214 10:48:40.231068 134013308572800 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nI0214 10:48:40.257250 134013308572800 config_util.py:552] Maybe overwriting train_steps: 45500\nI0214 10:48:40.257427 134013308572800 config_util.py:552] Maybe overwriting use_bfloat16: False\nW0214 10:48:40.298784 134013308572800 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\nInstructions for updating:\nrename to distribute_datasets_from_function\nI0214 10:48:40.307060 134013308572800 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/dataset/train.record']\nI0214 10:48:40.307259 134013308572800 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/dataset/train.record']\nI0214 10:48:40.307350 134013308572800 dataset_builder.py:80] Number of filenames to read: 1\nW0214 10:48:40.307438 134013308572800 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0214 10:48:40.314379 134013308572800 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0214 10:48:40.332024 134013308572800 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0214 10:48:46.138256 134013308572800 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0214 10:48:48.636195 134013308572800 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\n/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn(\nI0214 10:48:56.941083 134007699260992 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\nW0214 10:49:04.596493 134007699260992 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:460: Tensor.experimental_ref (from tensorflow.python.framework.tensor) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse ref() instead.\nW0214 10:49:09.321817 134007699260992 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee `tf.nn.softmax_cross_entropy_with_logits_v2`.\n\nI0214 10:49:48.532462 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.536431 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.537645 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.538747 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.541632 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.542982 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.544336 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.545436 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.548217 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:49:48.549335 134013308572800 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0214 10:50:06.504824 134013308572800 cross_device_ops.py:1154] Collective all_reduce tensors: 169 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nI0214 10:50:25.403314 134013308572800 cross_device_ops.py:1154] Collective all_reduce tensors: 169 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nI0214 10:50:43.532665 134013308572800 cross_device_ops.py:1154] Collective all_reduce tensors: 169 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nI0214 10:51:02.430793 134013308572800 cross_device_ops.py:1154] Collective all_reduce tensors: 169 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nI0214 10:52:41.305297 134013308572800 model_lib_v2.py:705] Step 100 per-step time 1.720s\nI0214 10:52:41.305682 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.4758035,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2997796,\n 'Loss/RPNLoss/localization_loss': 0.19047698,\n 'Loss/RPNLoss/objectness_loss': 0.090237185,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0562973,\n 'learning_rate': 0.014666351}\nI0214 10:53:45.599582 134013308572800 model_lib_v2.py:705] Step 200 per-step time 0.643s\nI0214 10:53:45.599947 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.4111085,\n 'Loss/BoxClassifierLoss/localization_loss': 0.42657706,\n 'Loss/RPNLoss/localization_loss': 0.22054711,\n 'Loss/RPNLoss/objectness_loss': 0.05185183,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.1100844,\n 'learning_rate': 0.0159997}\nI0214 10:54:49.570102 134013308572800 model_lib_v2.py:705] Step 300 per-step time 0.640s\nI0214 10:54:49.570508 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.52999395,\n 'Loss/BoxClassifierLoss/localization_loss': 0.32480997,\n 'Loss/RPNLoss/localization_loss': 0.115849644,\n 'Loss/RPNLoss/objectness_loss': 0.09006226,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0607159,\n 'learning_rate': 0.01733305}\nI0214 10:55:52.716361 134013308572800 model_lib_v2.py:705] Step 400 per-step time 0.631s\nI0214 10:55:52.716726 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.36384463,\n 'Loss/BoxClassifierLoss/localization_loss': 0.521542,\n 'Loss/RPNLoss/localization_loss': 0.29623538,\n 'Loss/RPNLoss/objectness_loss': 0.05685481,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.2384768,\n 'learning_rate': 0.0186664}\nI0214 10:56:55.808453 134013308572800 model_lib_v2.py:705] Step 500 per-step time 0.631s\nI0214 10:56:55.808842 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.47003987,\n 'Loss/BoxClassifierLoss/localization_loss': 0.45650077,\n 'Loss/RPNLoss/localization_loss': 0.069363914,\n 'Loss/RPNLoss/objectness_loss': 0.054885898,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0507904,\n 'learning_rate': 0.01999975}\nI0214 10:57:59.032822 134013308572800 model_lib_v2.py:705] Step 600 per-step time 0.632s\nI0214 10:57:59.033160 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.59006834,\n 'Loss/BoxClassifierLoss/localization_loss': 0.56356144,\n 'Loss/RPNLoss/localization_loss': 0.37258905,\n 'Loss/RPNLoss/objectness_loss': 0.11148851,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.6377075,\n 'learning_rate': 0.0213331}\nI0214 10:59:03.617621 134013308572800 model_lib_v2.py:705] Step 700 per-step time 0.646s\nI0214 10:59:03.617985 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.60879374,\n 'Loss/BoxClassifierLoss/localization_loss': 0.26061338,\n 'Loss/RPNLoss/localization_loss': 0.25221008,\n 'Loss/RPNLoss/objectness_loss': 0.06623216,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.1878493,\n 'learning_rate': 0.02266645}\nI0214 11:00:07.860746 134013308572800 model_lib_v2.py:705] Step 800 per-step time 0.642s\nI0214 11:00:07.861090 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.4253148,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2645916,\n 'Loss/RPNLoss/localization_loss': 0.3094716,\n 'Loss/RPNLoss/objectness_loss': 0.07772219,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0771002,\n 'learning_rate': 0.023999799}\nI0214 11:01:11.341770 134013308572800 model_lib_v2.py:705] Step 900 per-step time 0.635s\nI0214 11:01:11.342110 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.3812245,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2515883,\n 'Loss/RPNLoss/localization_loss': 0.2998865,\n 'Loss/RPNLoss/objectness_loss': 0.055395864,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.98809516,\n 'learning_rate': 0.025333151}\nI0214 11:02:15.678508 134013308572800 model_lib_v2.py:705] Step 1000 per-step time 0.643s\nI0214 11:02:15.678872 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.32693166,\n 'Loss/BoxClassifierLoss/localization_loss': 0.5437081,\n 'Loss/RPNLoss/localization_loss': 0.13096751,\n 'Loss/RPNLoss/objectness_loss': 0.056464326,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0580716,\n 'learning_rate': 0.0266665}\nI0214 11:03:19.449268 134013308572800 model_lib_v2.py:705] Step 1100 per-step time 0.638s\nI0214 11:03:19.449610 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.27500585,\n 'Loss/BoxClassifierLoss/localization_loss': 0.3309542,\n 'Loss/RPNLoss/localization_loss': 0.25541332,\n 'Loss/RPNLoss/objectness_loss': 0.06654863,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.927922,\n 'learning_rate': 0.02799985}\nI0214 11:04:22.804691 134013308572800 model_lib_v2.py:705] Step 1200 per-step time 0.634s\nI0214 11:04:22.805054 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.32640386,\n 'Loss/BoxClassifierLoss/localization_loss': 0.34811306,\n 'Loss/RPNLoss/localization_loss': 0.35745734,\n 'Loss/RPNLoss/objectness_loss': 0.063410506,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0953847,\n 'learning_rate': 0.0293332}\nI0214 11:05:25.785908 134013308572800 model_lib_v2.py:705] Step 1300 per-step time 0.630s\nI0214 11:05:25.786243 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.505652,\n 'Loss/BoxClassifierLoss/localization_loss': 0.3318964,\n 'Loss/RPNLoss/localization_loss': 0.038048945,\n 'Loss/RPNLoss/objectness_loss': 0.08285241,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.9584497,\n 'learning_rate': 0.03066655}\nI0214 11:06:29.165076 134013308572800 model_lib_v2.py:705] Step 1400 per-step time 0.634s\nI0214 11:06:29.165441 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.45250335,\n 'Loss/BoxClassifierLoss/localization_loss': 0.4538989,\n 'Loss/RPNLoss/localization_loss': 0.10505037,\n 'Loss/RPNLoss/objectness_loss': 0.09809476,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.1095474,\n 'learning_rate': 0.0319999}\nI0214 11:07:32.504730 134013308572800 model_lib_v2.py:705] Step 1500 per-step time 0.633s\nI0214 11:07:32.505086 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.39143252,\n 'Loss/BoxClassifierLoss/localization_loss': 0.42512184,\n 'Loss/RPNLoss/localization_loss': 0.19390044,\n 'Loss/RPNLoss/objectness_loss': 0.038824596,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0492795,\n 'learning_rate': 0.03333325}\nI0214 11:08:35.554045 134013308572800 model_lib_v2.py:705] Step 1600 per-step time 0.631s\nI0214 11:08:35.554389 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.47862273,\n 'Loss/BoxClassifierLoss/localization_loss': 0.4424822,\n 'Loss/RPNLoss/localization_loss': 0.14796418,\n 'Loss/RPNLoss/objectness_loss': 0.06841446,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.1374836,\n 'learning_rate': 0.034666598}\nI0214 11:09:39.061325 134013308572800 model_lib_v2.py:705] Step 1700 per-step time 0.635s\nI0214 11:09:39.061695 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.34013888,\n 'Loss/BoxClassifierLoss/localization_loss': 0.33187747,\n 'Loss/RPNLoss/localization_loss': 0.2626288,\n 'Loss/RPNLoss/objectness_loss': 0.06680321,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0014484,\n 'learning_rate': 0.03599995}\nI0214 11:10:42.713613 134013308572800 model_lib_v2.py:705] Step 1800 per-step time 0.637s\nI0214 11:10:42.713954 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.46870548,\n 'Loss/BoxClassifierLoss/localization_loss': 0.26242638,\n 'Loss/RPNLoss/localization_loss': 0.23201367,\n 'Loss/RPNLoss/objectness_loss': 0.06718273,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0303283,\n 'learning_rate': 0.037333302}\nI0214 11:11:46.367607 134013308572800 model_lib_v2.py:705] Step 1900 per-step time 0.637s\nI0214 11:11:46.367962 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.34954476,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2543596,\n 'Loss/RPNLoss/localization_loss': 0.22689876,\n 'Loss/RPNLoss/objectness_loss': 0.07310206,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.9039053,\n 'learning_rate': 0.03866665}\nI0214 11:12:49.931139 134013308572800 model_lib_v2.py:705] Step 2000 per-step time 0.636s\nI0214 11:12:49.931509 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.40868798,\n 'Loss/BoxClassifierLoss/localization_loss': 0.49753058,\n 'Loss/RPNLoss/localization_loss': 0.07593642,\n 'Loss/RPNLoss/objectness_loss': 0.07030397,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.052459,\n 'learning_rate': 0.04}\nI0214 11:13:53.219279 134013308572800 model_lib_v2.py:705] Step 2100 per-step time 0.633s\nI0214 11:13:53.219614 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.28887045,\n 'Loss/BoxClassifierLoss/localization_loss': 0.24884892,\n 'Loss/RPNLoss/localization_loss': 0.122529216,\n 'Loss/RPNLoss/objectness_loss': 0.057619758,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.7178683,\n 'learning_rate': 0.039998136}\nI0214 11:14:56.369301 134013308572800 model_lib_v2.py:705] Step 2200 per-step time 0.631s\nI0214 11:14:56.369678 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.41813585,\n 'Loss/BoxClassifierLoss/localization_loss': 0.23069572,\n 'Loss/RPNLoss/localization_loss': 0.26379704,\n 'Loss/RPNLoss/objectness_loss': 0.06739342,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.9800221,\n 'learning_rate': 0.039992537}\nI0214 11:15:59.541057 134013308572800 model_lib_v2.py:705] Step 2300 per-step time 0.632s\nI0214 11:15:59.541458 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.36795795,\n 'Loss/BoxClassifierLoss/localization_loss': 0.41586173,\n 'Loss/RPNLoss/localization_loss': 0.14733657,\n 'Loss/RPNLoss/objectness_loss': 0.044360958,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.97551715,\n 'learning_rate': 0.03998321}\nI0214 11:17:02.660403 134013308572800 model_lib_v2.py:705] Step 2400 per-step time 0.631s\nI0214 11:17:02.660767 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.32366145,\n 'Loss/BoxClassifierLoss/localization_loss': 0.33746806,\n 'Loss/RPNLoss/localization_loss': 0.17668653,\n 'Loss/RPNLoss/objectness_loss': 0.059511367,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.8973274,\n 'learning_rate': 0.039970152}\nI0214 11:18:05.631762 134013308572800 model_lib_v2.py:705] Step 2500 per-step time 0.630s\nI0214 11:18:05.632091 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.48798954,\n 'Loss/BoxClassifierLoss/localization_loss': 0.36284596,\n 'Loss/RPNLoss/localization_loss': 0.1180411,\n 'Loss/RPNLoss/objectness_loss': 0.04612068,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0149972,\n 'learning_rate': 0.039953373}\nI0214 11:19:08.713049 134013308572800 model_lib_v2.py:705] Step 2600 per-step time 0.631s\nI0214 11:19:08.713379 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.3898738,\n 'Loss/BoxClassifierLoss/localization_loss': 0.42012268,\n 'Loss/RPNLoss/localization_loss': 0.23997943,\n 'Loss/RPNLoss/objectness_loss': 0.08491105,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.134887,\n 'learning_rate': 0.03993287}\nI0214 11:20:11.113075 134013308572800 model_lib_v2.py:705] Step 2700 per-step time 0.624s\nI0214 11:20:11.113430 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.30029303,\n 'Loss/BoxClassifierLoss/localization_loss': 0.3526041,\n 'Loss/RPNLoss/localization_loss': 0.28059158,\n 'Loss/RPNLoss/objectness_loss': 0.081203654,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0146923,\n 'learning_rate': 0.039908648}\nI0214 11:21:14.187534 134013308572800 model_lib_v2.py:705] Step 2800 per-step time 0.631s\nI0214 11:21:14.187891 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.18001112,\n 'Loss/BoxClassifierLoss/localization_loss': 0.19601992,\n 'Loss/RPNLoss/localization_loss': 0.44937098,\n 'Loss/RPNLoss/objectness_loss': 0.11267649,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.9380785,\n 'learning_rate': 0.039880715}\nI0214 11:22:17.843787 134013308572800 model_lib_v2.py:705] Step 2900 per-step time 0.637s\nI0214 11:22:17.844154 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.35733414,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2178692,\n 'Loss/RPNLoss/localization_loss': 0.4231434,\n 'Loss/RPNLoss/objectness_loss': 0.068087965,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0664347,\n 'learning_rate': 0.039849065}\nI0214 11:23:21.251615 134013308572800 model_lib_v2.py:705] Step 3000 per-step time 0.634s\nI0214 11:23:21.251965 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.39192724,\n 'Loss/BoxClassifierLoss/localization_loss': 0.1887987,\n 'Loss/RPNLoss/localization_loss': 0.12710726,\n 'Loss/RPNLoss/objectness_loss': 0.055019718,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.7628529,\n 'learning_rate': 0.03981372}\nI0214 11:24:24.793893 134013308572800 model_lib_v2.py:705] Step 3100 per-step time 0.635s\nI0214 11:24:24.794272 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.3516218,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2190702,\n 'Loss/RPNLoss/localization_loss': 0.24335557,\n 'Loss/RPNLoss/objectness_loss': 0.049615458,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.8636631,\n 'learning_rate': 0.03977467}\nI0214 11:25:27.659427 134013308572800 model_lib_v2.py:705] Step 3200 per-step time 0.629s\nI0214 11:25:27.659782 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.2844265,\n 'Loss/BoxClassifierLoss/localization_loss': 0.25179392,\n 'Loss/RPNLoss/localization_loss': 0.35140082,\n 'Loss/RPNLoss/objectness_loss': 0.036064316,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.92368555,\n 'learning_rate': 0.03973194}\nI0214 11:26:30.579678 134013308572800 model_lib_v2.py:705] Step 3300 per-step time 0.629s\nI0214 11:26:30.580036 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.31750602,\n 'Loss/BoxClassifierLoss/localization_loss': 0.22200395,\n 'Loss/RPNLoss/localization_loss': 0.07284126,\n 'Loss/RPNLoss/objectness_loss': 0.05397684,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.6663281,\n 'learning_rate': 0.03968552}\nI0214 11:27:33.480508 134013308572800 model_lib_v2.py:705] Step 3400 per-step time 0.629s\nI0214 11:27:33.480845 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.2545607,\n 'Loss/BoxClassifierLoss/localization_loss': 0.36520457,\n 'Loss/RPNLoss/localization_loss': 0.13108069,\n 'Loss/RPNLoss/objectness_loss': 0.073075466,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.82392144,\n 'learning_rate': 0.039635435}\nI0214 11:28:36.252760 134013308572800 model_lib_v2.py:705] Step 3500 per-step time 0.628s\nI0214 11:28:36.253098 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.27013642,\n 'Loss/BoxClassifierLoss/localization_loss': 0.3242981,\n 'Loss/RPNLoss/localization_loss': 0.26927173,\n 'Loss/RPNLoss/objectness_loss': 0.030342545,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.8940488,\n 'learning_rate': 0.03958168}\nI0214 11:29:38.879376 134013308572800 model_lib_v2.py:705] Step 3600 per-step time 0.626s\nI0214 11:29:38.879818 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.32117215,\n 'Loss/BoxClassifierLoss/localization_loss': 0.3010738,\n 'Loss/RPNLoss/localization_loss': 0.09158281,\n 'Loss/RPNLoss/objectness_loss': 0.022647899,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.73647666,\n 'learning_rate': 0.039524276}\nI0214 11:30:41.458615 134013308572800 model_lib_v2.py:705] Step 3700 per-step time 0.626s\nI0214 11:30:41.458985 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.38997018,\n 'Loss/BoxClassifierLoss/localization_loss': 0.46826982,\n 'Loss/RPNLoss/localization_loss': 0.15142491,\n 'Loss/RPNLoss/objectness_loss': 0.05211641,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.0617813,\n 'learning_rate': 0.03946323}\nI0214 11:31:44.061928 134013308572800 model_lib_v2.py:705] Step 3800 per-step time 0.626s\nI0214 11:31:44.062282 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.20516227,\n 'Loss/BoxClassifierLoss/localization_loss': 0.20748338,\n 'Loss/RPNLoss/localization_loss': 0.08058098,\n 'Loss/RPNLoss/objectness_loss': 0.03149941,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.52472603,\n 'learning_rate': 0.039398547}\nI0214 11:32:47.022670 134013308572800 model_lib_v2.py:705] Step 3900 per-step time 0.630s\nI0214 11:32:47.023280 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.33559912,\n 'Loss/BoxClassifierLoss/localization_loss': 0.26857167,\n 'Loss/RPNLoss/localization_loss': 0.10955295,\n 'Loss/RPNLoss/objectness_loss': 0.04529893,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.75902265,\n 'learning_rate': 0.039330248}\nI0214 11:33:50.052922 134013308572800 model_lib_v2.py:705] Step 4000 per-step time 0.630s\nI0214 11:33:50.053231 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.32569286,\n 'Loss/BoxClassifierLoss/localization_loss': 0.15434197,\n 'Loss/RPNLoss/localization_loss': 0.20843875,\n 'Loss/RPNLoss/objectness_loss': 0.03269505,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.72116864,\n 'learning_rate': 0.039258346}\nI0214 11:34:53.652455 134013308572800 model_lib_v2.py:705] Step 4100 per-step time 0.636s\nI0214 11:34:53.652817 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.29062998,\n 'Loss/BoxClassifierLoss/localization_loss': 0.298095,\n 'Loss/RPNLoss/localization_loss': 0.13183892,\n 'Loss/RPNLoss/objectness_loss': 0.06553002,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.7860939,\n 'learning_rate': 0.03918285}\nI0214 11:35:56.808684 134013308572800 model_lib_v2.py:705] Step 4200 per-step time 0.632s\nI0214 11:35:56.808999 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.2700008,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2264067,\n 'Loss/RPNLoss/localization_loss': 0.3831334,\n 'Loss/RPNLoss/objectness_loss': 0.08365279,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.96319366,\n 'learning_rate': 0.03910377}\nI0214 11:36:59.669488 134013308572800 model_lib_v2.py:705] Step 4300 per-step time 0.629s\nI0214 11:36:59.669934 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.31097174,\n 'Loss/BoxClassifierLoss/localization_loss': 0.20289591,\n 'Loss/RPNLoss/localization_loss': 0.2725106,\n 'Loss/RPNLoss/objectness_loss': 0.04418863,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.8305668,\n 'learning_rate': 0.039021127}\nI0214 11:38:02.511452 134013308572800 model_lib_v2.py:705] Step 4400 per-step time 0.628s\nI0214 11:38:02.511822 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.20773362,\n 'Loss/BoxClassifierLoss/localization_loss': 0.32064158,\n 'Loss/RPNLoss/localization_loss': 0.21370772,\n 'Loss/RPNLoss/objectness_loss': 0.06176246,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.8038454,\n 'learning_rate': 0.03893494}\nI0214 11:39:05.826162 134013308572800 model_lib_v2.py:705] Step 4500 per-step time 0.633s\nI0214 11:39:05.826506 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.2000001,\n 'Loss/BoxClassifierLoss/localization_loss': 0.281518,\n 'Loss/RPNLoss/localization_loss': 0.1854748,\n 'Loss/RPNLoss/objectness_loss': 0.03759018,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.7045831,\n 'learning_rate': 0.03884522}\nI0214 11:40:08.959690 134013308572800 model_lib_v2.py:705] Step 4600 per-step time 0.631s\nI0214 11:40:08.960041 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.19242236,\n 'Loss/BoxClassifierLoss/localization_loss': 0.19601223,\n 'Loss/RPNLoss/localization_loss': 0.18700874,\n 'Loss/RPNLoss/objectness_loss': 0.02670262,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.60214597,\n 'learning_rate': 0.03875198}\nI0214 11:41:11.330951 134013308572800 model_lib_v2.py:705] Step 4700 per-step time 0.624s\nI0214 11:41:11.331305 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.2716605,\n 'Loss/BoxClassifierLoss/localization_loss': 0.4362135,\n 'Loss/RPNLoss/localization_loss': 0.22171116,\n 'Loss/RPNLoss/objectness_loss': 0.06947714,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.9990623,\n 'learning_rate': 0.038655244}\nI0214 11:42:13.798766 134013308572800 model_lib_v2.py:705] Step 4800 per-step time 0.625s\nI0214 11:42:13.799127 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.22824506,\n 'Loss/BoxClassifierLoss/localization_loss': 0.29713303,\n 'Loss/RPNLoss/localization_loss': 0.03918524,\n 'Loss/RPNLoss/objectness_loss': 0.023584075,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.5881474,\n 'learning_rate': 0.038555026}\nI0214 11:43:16.382508 134013308572800 model_lib_v2.py:705] Step 4900 per-step time 0.626s\nI0214 11:43:16.382850 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.33132747,\n 'Loss/BoxClassifierLoss/localization_loss': 0.32462513,\n 'Loss/RPNLoss/localization_loss': 0.41618997,\n 'Loss/RPNLoss/objectness_loss': 0.035096828,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 1.1072395,\n 'learning_rate': 0.038451348}\nI0214 11:44:18.981462 134013308572800 model_lib_v2.py:705] Step 5000 per-step time 0.626s\nI0214 11:44:18.981816 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.31018257,\n 'Loss/BoxClassifierLoss/localization_loss': 0.25623858,\n 'Loss/RPNLoss/localization_loss': 0.14509666,\n 'Loss/RPNLoss/objectness_loss': 0.0640499,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.7755677,\n 'learning_rate': 0.038344227}\nI0214 11:45:23.273506 134013308572800 model_lib_v2.py:705] Step 5100 per-step time 0.643s\nI0214 11:45:23.273858 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.3209138,\n 'Loss/BoxClassifierLoss/localization_loss': 0.20426306,\n 'Loss/RPNLoss/localization_loss': 0.21965435,\n 'Loss/RPNLoss/objectness_loss': 0.058966354,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.8037976,\n 'learning_rate': 0.03823368}\nI0214 11:46:26.316735 134013308572800 model_lib_v2.py:705] Step 5200 per-step time 0.630s\nI0214 11:46:26.317095 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.22605935,\n 'Loss/BoxClassifierLoss/localization_loss': 0.14286493,\n 'Loss/RPNLoss/localization_loss': 0.3003471,\n 'Loss/RPNLoss/objectness_loss': 0.08719042,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.75646174,\n 'learning_rate': 0.038119733}\nI0214 11:47:29.219191 134013308572800 model_lib_v2.py:705] Step 5300 per-step time 0.629s\nI0214 11:47:29.219553 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.21614626,\n 'Loss/BoxClassifierLoss/localization_loss': 0.1500135,\n 'Loss/RPNLoss/localization_loss': 0.14553417,\n 'Loss/RPNLoss/objectness_loss': 0.034119938,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.5458139,\n 'learning_rate': 0.03800241}\nI0214 11:48:31.994401 134013308572800 model_lib_v2.py:705] Step 5400 per-step time 0.628s\nI0214 11:48:31.994820 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.3540187,\n 'Loss/BoxClassifierLoss/localization_loss': 0.21668877,\n 'Loss/RPNLoss/localization_loss': 0.10025868,\n 'Loss/RPNLoss/objectness_loss': 0.053632952,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.724599,\n 'learning_rate': 0.037881725}\nI0214 11:49:34.701267 134013308572800 model_lib_v2.py:705] Step 5500 per-step time 0.627s\nI0214 11:49:34.701647 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.17714635,\n 'Loss/BoxClassifierLoss/localization_loss': 0.16857982,\n 'Loss/RPNLoss/localization_loss': 0.26306152,\n 'Loss/RPNLoss/objectness_loss': 0.02529256,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.6340803,\n 'learning_rate': 0.037757702}\nI0214 11:50:37.441998 134013308572800 model_lib_v2.py:705] Step 5600 per-step time 0.627s\nI0214 11:50:37.442334 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.25029278,\n 'Loss/BoxClassifierLoss/localization_loss': 0.16496965,\n 'Loss/RPNLoss/localization_loss': 0.27232352,\n 'Loss/RPNLoss/objectness_loss': 0.028591564,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.7161776,\n 'learning_rate': 0.03763037}\nI0214 11:51:40.222105 134013308572800 model_lib_v2.py:705] Step 5700 per-step time 0.628s\nI0214 11:51:40.222459 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.26893598,\n 'Loss/BoxClassifierLoss/localization_loss': 0.18023914,\n 'Loss/RPNLoss/localization_loss': 0.25046834,\n 'Loss/RPNLoss/objectness_loss': 0.054290675,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.75393414,\n 'learning_rate': 0.03749975}\nI0214 11:52:42.625206 134013308572800 model_lib_v2.py:705] Step 5800 per-step time 0.624s\nI0214 11:52:42.625555 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.21655425,\n 'Loss/BoxClassifierLoss/localization_loss': 0.16249618,\n 'Loss/RPNLoss/localization_loss': 0.10870303,\n 'Loss/RPNLoss/objectness_loss': 0.042978447,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.5307319,\n 'learning_rate': 0.037365858}\nI0214 11:53:45.117264 134013308572800 model_lib_v2.py:705] Step 5900 per-step time 0.625s\nI0214 11:53:45.117599 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.24356547,\n 'Loss/BoxClassifierLoss/localization_loss': 0.27510694,\n 'Loss/RPNLoss/localization_loss': 0.24935201,\n 'Loss/RPNLoss/objectness_loss': 0.036216,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.8042404,\n 'learning_rate': 0.03722873}\nI0214 11:54:47.772643 134013308572800 model_lib_v2.py:705] Step 6000 per-step time 0.627s\nI0214 11:54:47.772998 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.30221778,\n 'Loss/BoxClassifierLoss/localization_loss': 0.40751764,\n 'Loss/RPNLoss/localization_loss': 0.07841991,\n 'Loss/RPNLoss/objectness_loss': 0.032981817,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.8211372,\n 'learning_rate': 0.037088387}\nI0214 11:55:50.234738 134013308572800 model_lib_v2.py:705] Step 6100 per-step time 0.625s\nI0214 11:55:50.235076 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.13523833,\n 'Loss/BoxClassifierLoss/localization_loss': 0.22028993,\n 'Loss/RPNLoss/localization_loss': 0.24562441,\n 'Loss/RPNLoss/objectness_loss': 0.021615721,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.6227684,\n 'learning_rate': 0.036944855}\nI0214 11:56:53.064418 134013308572800 model_lib_v2.py:705] Step 6200 per-step time 0.628s\nI0214 11:56:53.064824 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.22782709,\n 'Loss/BoxClassifierLoss/localization_loss': 0.13992596,\n 'Loss/RPNLoss/localization_loss': 0.18580633,\n 'Loss/RPNLoss/objectness_loss': 0.057461493,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.61102086,\n 'learning_rate': 0.036798168}\nI0214 11:57:56.062798 134013308572800 model_lib_v2.py:705] Step 6300 per-step time 0.630s\nI0214 11:57:56.063155 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.26348907,\n 'Loss/BoxClassifierLoss/localization_loss': 0.09952159,\n 'Loss/RPNLoss/localization_loss': 0.17586017,\n 'Loss/RPNLoss/objectness_loss': 0.024180228,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.5630511,\n 'learning_rate': 0.03664834}\nI0214 11:58:58.884403 134013308572800 model_lib_v2.py:705] Step 6400 per-step time 0.628s\nI0214 11:58:58.884763 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.22735327,\n 'Loss/BoxClassifierLoss/localization_loss': 0.157828,\n 'Loss/RPNLoss/localization_loss': 0.07851032,\n 'Loss/RPNLoss/objectness_loss': 0.02441349,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.48810512,\n 'learning_rate': 0.03649541}\nI0214 12:00:01.641062 134013308572800 model_lib_v2.py:705] Step 6500 per-step time 0.628s\nI0214 12:00:01.641395 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.1428133,\n 'Loss/BoxClassifierLoss/localization_loss': 0.11644204,\n 'Loss/RPNLoss/localization_loss': 0.13502766,\n 'Loss/RPNLoss/objectness_loss': 0.04107832,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.4353613,\n 'learning_rate': 0.0363394}\nI0214 12:01:04.160531 134013308572800 model_lib_v2.py:705] Step 6600 per-step time 0.625s\nI0214 12:01:04.160896 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.19698954,\n 'Loss/BoxClassifierLoss/localization_loss': 0.14483686,\n 'Loss/RPNLoss/localization_loss': 0.20969711,\n 'Loss/RPNLoss/objectness_loss': 0.012562866,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.5640864,\n 'learning_rate': 0.03618034}\nI0214 12:02:06.681064 134013308572800 model_lib_v2.py:705] Step 6700 per-step time 0.625s\nI0214 12:02:06.681473 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.28624916,\n 'Loss/BoxClassifierLoss/localization_loss': 0.20713207,\n 'Loss/RPNLoss/localization_loss': 0.2269723,\n 'Loss/RPNLoss/objectness_loss': 0.031934634,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.7522882,\n 'learning_rate': 0.03601826}\nI0214 12:03:08.866111 134013308572800 model_lib_v2.py:705] Step 6800 per-step time 0.622s\nI0214 12:03:08.866649 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.15764245,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2851569,\n 'Loss/RPNLoss/localization_loss': 0.023016194,\n 'Loss/RPNLoss/objectness_loss': 0.0204029,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.4862185,\n 'learning_rate': 0.035853196}\nI0214 12:04:11.362221 134013308572800 model_lib_v2.py:705] Step 6900 per-step time 0.625s\nI0214 12:04:11.362580 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.23216774,\n 'Loss/BoxClassifierLoss/localization_loss': 0.14761767,\n 'Loss/RPNLoss/localization_loss': 0.2119631,\n 'Loss/RPNLoss/objectness_loss': 0.06944145,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.66119,\n 'learning_rate': 0.035685178}\nI0214 12:05:13.939223 134013308572800 model_lib_v2.py:705] Step 7000 per-step time 0.626s\nI0214 12:05:13.939611 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.23223493,\n 'Loss/BoxClassifierLoss/localization_loss': 0.24204421,\n 'Loss/RPNLoss/localization_loss': 0.23597468,\n 'Loss/RPNLoss/objectness_loss': 0.03129646,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.74155027,\n 'learning_rate': 0.035514224}\nI0214 12:06:16.676600 134013308572800 model_lib_v2.py:705] Step 7100 per-step time 0.627s\nI0214 12:06:16.676941 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.24405012,\n 'Loss/BoxClassifierLoss/localization_loss': 0.21851298,\n 'Loss/RPNLoss/localization_loss': 0.14678892,\n 'Loss/RPNLoss/objectness_loss': 0.0122978315,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.62164986,\n 'learning_rate': 0.035340384}\nI0214 12:07:19.420189 134013308572800 model_lib_v2.py:705] Step 7200 per-step time 0.627s\nI0214 12:07:19.420574 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.25120157,\n 'Loss/BoxClassifierLoss/localization_loss': 0.20910498,\n 'Loss/RPNLoss/localization_loss': 0.22900698,\n 'Loss/RPNLoss/objectness_loss': 0.03713769,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.7264512,\n 'learning_rate': 0.035163675}\nI0214 12:08:22.211328 134013308572800 model_lib_v2.py:705] Step 7300 per-step time 0.628s\nI0214 12:08:22.211730 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.25959632,\n 'Loss/BoxClassifierLoss/localization_loss': 0.18007568,\n 'Loss/RPNLoss/localization_loss': 0.22047903,\n 'Loss/RPNLoss/objectness_loss': 0.06558956,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.72574055,\n 'learning_rate': 0.034984138}\nI0214 12:09:24.781280 134013308572800 model_lib_v2.py:705] Step 7400 per-step time 0.626s\nI0214 12:09:24.781657 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.20611936,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2214731,\n 'Loss/RPNLoss/localization_loss': 0.034660675,\n 'Loss/RPNLoss/objectness_loss': 0.030150233,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.4924034,\n 'learning_rate': 0.03480181}\nI0214 12:10:27.655099 134013308572800 model_lib_v2.py:705] Step 7500 per-step time 0.629s\nI0214 12:10:27.655464 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.20427898,\n 'Loss/BoxClassifierLoss/localization_loss': 0.20637172,\n 'Loss/RPNLoss/localization_loss': 0.13513407,\n 'Loss/RPNLoss/objectness_loss': 0.021966109,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.5677509,\n 'learning_rate': 0.034616716}\nI0214 12:11:30.364027 134013308572800 model_lib_v2.py:705] Step 7600 per-step time 0.627s\nI0214 12:11:30.364352 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.14963834,\n 'Loss/BoxClassifierLoss/localization_loss': 0.1776586,\n 'Loss/RPNLoss/localization_loss': 0.07941602,\n 'Loss/RPNLoss/objectness_loss': 0.026079599,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.43279254,\n 'learning_rate': 0.0344289}\nI0214 12:12:32.701071 134013308572800 model_lib_v2.py:705] Step 7700 per-step time 0.623s\nI0214 12:12:32.701558 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.27374214,\n 'Loss/BoxClassifierLoss/localization_loss': 0.2301127,\n 'Loss/RPNLoss/localization_loss': 0.14880288,\n 'Loss/RPNLoss/objectness_loss': 0.028191777,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.6808495,\n 'learning_rate': 0.03423839}\nI0214 12:13:34.905850 134013308572800 model_lib_v2.py:705] Step 7800 per-step time 0.622s\nI0214 12:13:34.906194 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.19943307,\n 'Loss/BoxClassifierLoss/localization_loss': 0.1547626,\n 'Loss/RPNLoss/localization_loss': 0.105266586,\n 'Loss/RPNLoss/objectness_loss': 0.022541668,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.48200393,\n 'learning_rate': 0.03404522}\nI0214 12:14:37.353446 134013308572800 model_lib_v2.py:705] Step 7900 per-step time 0.624s\nI0214 12:14:37.353794 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.105287746,\n 'Loss/BoxClassifierLoss/localization_loss': 0.24310356,\n 'Loss/RPNLoss/localization_loss': 0.09285785,\n 'Loss/RPNLoss/objectness_loss': 0.018647244,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.45989642,\n 'learning_rate': 0.033849433}\nI0214 12:15:39.339316 134013308572800 model_lib_v2.py:705] Step 8000 per-step time 0.620s\nI0214 12:15:39.339664 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.2900207,\n 'Loss/BoxClassifierLoss/localization_loss': 0.28171703,\n 'Loss/RPNLoss/localization_loss': 0.11375416,\n 'Loss/RPNLoss/objectness_loss': 0.023834236,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.70932615,\n 'learning_rate': 0.03365106}\nI0214 12:16:41.986429 134013308572800 model_lib_v2.py:705] Step 8100 per-step time 0.626s\nI0214 12:16:41.986772 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.13526331,\n 'Loss/BoxClassifierLoss/localization_loss': 0.13832715,\n 'Loss/RPNLoss/localization_loss': 0.08687571,\n 'Loss/RPNLoss/objectness_loss': 0.01984937,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.3803155,\n 'learning_rate': 0.033450145}\nI0214 12:17:44.584325 134013308572800 model_lib_v2.py:705] Step 8200 per-step time 0.626s\nI0214 12:17:44.584684 134013308572800 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.14865534,\n 'Loss/BoxClassifierLoss/localization_loss': 0.18425803,\n 'Loss/RPNLoss/localization_loss': 0.12414549,\n 'Loss/RPNLoss/objectness_loss': 0.02161604,\n 'Loss/regularization_loss': 0.0,\n 'Loss/total_loss': 0.4786749,\n 'learning_rate': 0.03324672}\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"file_path = \"/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py\"\n\n# Load the file and edit its content\nwith open(file_path, \"r\") as file:\n    code = file.readlines()\n\n# Add `import tensorflow as tf` at the top if not present\nif \"import tensorflow as tf\" not in code[0]:\n    code.insert(0, \"import tensorflow as tf\\n\")\n\n# Replace `control_flow_ops.case` with `tf.case` in the entire file\ncode = [line.replace(\"control_flow_ops.case\", \"tf.case\") for line in code]\n\n# Save the changes back to the file\nwith open(file_path, \"w\") as file:\n    file.writelines(code)\n\nprint(\"File updated successfully!\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSQmWSQPLgTV","outputId":"7d42192a-f6d6-4acc-cf56-5348e089fee6","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:45:55.788433Z","iopub.execute_input":"2025-02-14T10:45:55.788781Z","iopub.status.idle":"2025-02-14T10:45:55.796181Z","shell.execute_reply.started":"2025-02-14T10:45:55.788752Z","shell.execute_reply":"2025-02-14T10:45:55.795312Z"}},"outputs":[{"name":"stdout","text":"File updated successfully!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"file_path = \"/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py\"\n\n# Load the file and edit its content\nwith open(file_path, \"r\") as file:\n    code = file.readlines()\n\n# Ensure `from __future__` imports are at the top\nfuture_imports = [line for line in code if line.startswith(\"from __future__\")]\nnon_future_imports = [line for line in code if not line.startswith(\"from __future__\")]\n\n# Add `import tensorflow as tf` after `__future__` imports\nif \"import tensorflow as tf\\n\" not in non_future_imports:\n    non_future_imports.insert(0, \"import tensorflow as tf\\n\")\n\n# Combine `__future__` imports with other lines\ncode = future_imports + non_future_imports\n\n# Replace `control_flow_ops.case` with `tf.case` in the entire file\ncode = [line.replace(\"control_flow_ops.case\", \"tf.case\") for line in code]\n\n# Save the changes back to the file\nwith open(file_path, \"w\") as file:\n    file.writelines(code)\n\nprint(\"File updated successfully!\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x63chuOTLsHG","outputId":"fef56d57-3cdb-4ddb-b62e-a97b85b64af1","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:45:58.824951Z","iopub.execute_input":"2025-02-14T10:45:58.825280Z","iopub.status.idle":"2025-02-14T10:45:58.833109Z","shell.execute_reply.started":"2025-02-14T10:45:58.825250Z","shell.execute_reply":"2025-02-14T10:45:58.832250Z"}},"outputs":[{"name":"stdout","text":"File updated successfully!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"file_path = \"/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py\"\n\n# Load the file\nwith open(file_path, \"r\") as file:\n    code = file.readlines()\n\n# Replace all uses of control_flow_ops\ncode = [line.replace(\"control_flow_ops.cond\", \"tf.cond\") for line in code]\ncode = [line.replace(\"control_flow_ops.case\", \"tf.case\") for line in code]\n\n# Save the updated file\nwith open(file_path, \"w\") as file:\n    file.writelines(code)\n\nprint(\"File updated successfully!\")\n","metadata":{"id":"tWeDCp1-MLEb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ded0a3a4-9994-4747-a572-b6c055555e06","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T10:46:01.461963Z","iopub.execute_input":"2025-02-14T10:46:01.462279Z","iopub.status.idle":"2025-02-14T10:46:01.468828Z","shell.execute_reply.started":"2025-02-14T10:46:01.462251Z","shell.execute_reply":"2025-02-14T10:46:01.468012Z"}},"outputs":[{"name":"stdout","text":"File updated successfully!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yrFi6xiW2ESl","outputId":"c6262a18-224e-4776-f3e8-3142d3c6cca9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n"]}],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n","metadata":{"id":"xS1bFeUCBtd-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4b88ca0-e0ac-49d1-b065-4615ca912122"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.15.1\n"]}],"execution_count":null},{"cell_type":"markdown","source":"## Export model inference graph","metadata":{"id":"U3GNLS4ywstA"}},{"cell_type":"code","source":"output_directory = 'inference_graph'\n\n!python /content/models/research/object_detection/exporter_main_v2.py \\\n    --trained_checkpoint_dir {model_dir} \\\n    --output_directory {output_directory} \\\n    --pipeline_config_path {pipeline_config_path}","metadata":{"id":"WcvbNjcZw2er","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8d11b8b-2a6c-486a-d0c3-c35062968539"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-12-19 13:55:05.175203: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-19 13:55:05.175256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-19 13:55:05.176638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-12-19 13:55:06.266262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-12-19 13:55:10.561097: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W1219 13:55:10.835455 133545054048256 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1219 13:55:19.049163 133545054048256 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:460: Tensor.experimental_ref (from tensorflow.python.framework.tensor) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use ref() instead.\n","W1219 13:55:26.914273 133545054048256 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:460: Tensor.experimental_ref (from tensorflow.python.framework.tensor) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use ref() instead.\n","I1219 13:55:35.305146 133545054048256 signature_serialization.py:156] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to mask_rcnn_keras_box_predictor_mask_rcnn_class_head_classpredictor_dense_biasadd_readvariableop_resource in the SavedModel.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7974f7c45b40>, because it is not built.\n","W1219 13:55:41.940485 133545054048256 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7974f7c45b40>, because it is not built.\n","I1219 13:56:18.269692 133545054048256 save.py:289] Found untraced functions such as FirstStageBoxPredictor_layer_call_fn, FirstStageBoxPredictor_layer_call_and_return_conditional_losses, mask_rcnn_keras_box_predictor_layer_call_fn, mask_rcnn_keras_box_predictor_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op while saving (showing 5 of 186). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: inference_graph/saved_model/assets\n","I1219 13:56:33.049325 133545054048256 builder_impl.py:801] Assets written to: inference_graph/saved_model/assets\n","I1219 13:56:34.047952 133545054048256 fingerprinting_utils.py:49] Writing fingerprint to inference_graph/saved_model/fingerprint.pb\n","INFO:tensorflow:Writing pipeline config file to inference_graph/pipeline.config\n","I1219 13:56:35.400795 133545054048256 config_util.py:253] Writing pipeline config file to inference_graph/pipeline.config\n"]}],"execution_count":26},{"cell_type":"markdown","source":"### Download model","metadata":{"id":"HAH4TYj-_dgB"}},{"cell_type":"code","source":"# Zip and download your new model to your system\nfrom google.colab import files\n!zip -r new_model.zip /content/{output_directory}/saved_model\nfiles.download(f'new_model.zip')","metadata":{"id":"LcWVXuGAxeZ4","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"80fa962f-4cc9-4654-81d3-4e8761f72897"},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/inference_graph/saved_model/ (stored 0%)\n","  adding: content/inference_graph/saved_model/variables/ (stored 0%)\n","  adding: content/inference_graph/saved_model/variables/variables.index (deflated 83%)\n","  adding: content/inference_graph/saved_model/variables/variables.data-00000-of-00001 (deflated 7%)\n","  adding: content/inference_graph/saved_model/saved_model.pb (deflated 93%)\n","  adding: content/inference_graph/saved_model/fingerprint.pb (stored 0%)\n","  adding: content/inference_graph/saved_model/assets/ (stored 0%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_75376dce-0898-44b2-9e3a-04a1fa3e14dc\", \"new_model.zip\", 235874534)"]},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Optional: save a copy of the training data to your drive in case you want to re-train later\nfrom google.colab import drive\ndrive.mount('/content/drive')\n!cp -r training/ drive/MyDrive/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nVqd20ja9ZBX","outputId":"a98c6984-bd14-4a53-fe0f-349b2698e02c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"execution_count":28}]}